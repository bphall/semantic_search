{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import time\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import twint\n",
    "import json\n",
    "from pprint import pprint\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#BeautifulSoup\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "# Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "# spacy for lemmatization\n",
    "import spacy\n",
    "\n",
    "# Plotting tools FOR TOPIC MODELING\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim  # don't skip this\n",
    "\n",
    "\n",
    "# Enable logging for gensim - optional  (I HAVEN'T USED THIS YET)\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
    "\n",
    "\n",
    "# NLTK Stop words -------------- ADD TO THESE AS WE SEE FIT\n",
    "from nltk.corpus import stopwords\n",
    "from wordcloud import WordCloud, STOPWORDS \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "\n",
    "import pickle\n",
    "\n",
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('display.max_rows', 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape Gutenberg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_page = requests.get('https://www.gutenberg.org/browse/scores/top')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(html_page.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Book URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_100 = []\n",
    "for link in soup.find_all('a'):\n",
    "    top_100.append(link.get('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_100 = top_100[19:119]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_100_names = []\n",
    "for link in soup.find_all('a'):\n",
    "    top_100_names.append(link.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_100_names = top_100_names[19:119]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rid_paren(book_name):\n",
    "    clean = ''.join(re.findall(r'\\b\\w+[^()\\d+]\\b', book_name))\n",
    "    return clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_names = []\n",
    "for i in top_100_names:\n",
    "    book_names.append(rid_paren(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_dict = {}\n",
    "titles = []\n",
    "for i in book_names:\n",
    "    try:\n",
    "        name_author = i.split(' by ')\n",
    "        book_dict[name_author[0]] = name_author[1]\n",
    "        titles.append(name_author[0])\n",
    "    except:\n",
    "        book_dict[i] = i\n",
    "        titles.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Book Texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_nums = []\n",
    "for i in top_100:\n",
    "    temp = re.findall(r'\\d+', i)\n",
    "    url_nums.append(int(temp[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexed_titles = {}\n",
    "indexed_urls = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for i in range(0,100):\n",
    "    indexed_titles[i] = titles[count]\n",
    "    indexed_urls[i] = url_nums[count]\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_text(num):\n",
    "    html_page = requests.get(f'https://www.gutenberg.org/files/{num}/{num}-h/{num}-h.htm')\n",
    "    soup = BeautifulSoup(html_page.content, 'html.parser')\n",
    "    paragraphs = soup.findAll('p')\n",
    "    \n",
    "    unclean_text = []\n",
    "    for i in paragraphs:\n",
    "        unclean_text.append(i.text)\n",
    "\n",
    "    unclean_text = ' '.join(unclean_text)\n",
    "\n",
    "    clean_text = re.sub('\\n', ' ', unclean_text)\n",
    "    clean_text = re.sub('\\r', ' ', clean_text)\n",
    "    clean_text = re.sub('\\xa0', '', clean_text)\n",
    "    clean_text = re.sub(' +', ' ', clean_text)\n",
    "    \n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AN EXAMPLE OF HOW TO GET A BOOK BY ITS NAME/INDEX DIRECTLY, TO BE USED IN FOR LOOP BELOW\n",
    "# wp = strip_text(indexed_urls[36])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline Stripper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "novel_dict = {}\n",
    "\n",
    "book_index = 50\n",
    "\n",
    "for i in url_nums[50:100]:\n",
    "    novel_dict[titles[book_index]] = strip_text(i)\n",
    "    book_index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Dubliners', 'Prestuplenie i nakazanieEnglish', 'Wuthering Heights', 'Siddhartha', 'The Brothers Karamazov', 'Tractatus Logico-Philosophicus', 'Narrative of the Life of Frederick Douglassan American Slave', 'Les Misérables', 'The Kama Sutra of Vatsyayana', 'The Republic', 'The Time Machine', 'The Souls of Black Folk', 'A Study in Scarlet', 'Essays of Michel de MontaigneComplete', 'Also sprach ZarathustraEnglish', \"Uncle Tom's Cabin\", 'The Jungle Book', 'The Jungle', \"The Devil's Dictionary\", 'The Prophet', \"Baron Trump's Marvellous Underground Journey\", 'The Slang DictionaryEtymologicalHistorical and Andecdotal', 'Postscripts', 'White Fang', 'Beyond Good and Evil', 'The Odyssey', \"Divine ComedyLongfellow's TranslationHell\", 'Three Men in a BoatTo Say Nothing of the Dogby Jerome Jerome', 'The Tale of Peter Rabbit', 'Leviathan', 'The Life and Adventures of Robinson Crusoe', 'Hard Times', \"Alice's Adventures in Wonderland\", 'The Valley of the Shadow', 'The Iliad', 'Don Quixote', 'The Sign of the Four', 'Anna Karenina', \"Gulliver's Travels into Several Remote Nations of the World\", 'David Copperfield', 'Experimental Mechanics', 'Sense and Sensibility', 'The Legend of Sleepy Hollow', \"La Navigation Aérienne L'aviation Et La Direction Des Aérostats Dans Les Temps Anciens Et Modernes\", 'Index of Project Gutenberg Works on Black History', 'Geschlecht und CharakterEnglish', 'The Turn of the Screw', 'Candide', 'An Index of The Divine Comedy', 'Second Treatise of Government'])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "novel_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(first_fifty, open(\"pickled_novel_dict_0_50\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 198440\r\n",
      "-rw-r--r--  1 braytonhall  staff    27B Apr  5 17:12 README.md\r\n",
      "-rw-r--r--  1 braytonhall  staff    11K Apr  6 00:23 main_scratch.ipynb\r\n",
      "-rw-r--r--  1 braytonhall  staff    33M Apr  6 00:02 pickled_novel_dict\r\n",
      "-rw-r--r--  1 braytonhall  staff    33M Apr  6 00:25 pickled_novel_dict_0_50\r\n",
      "-rw-r--r--  1 braytonhall  staff    31M Apr  6 00:22 pickled_novel_dict_50_100\r\n"
     ]
    }
   ],
   "source": [
    "ls -lh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_fifty = pickle.load( open( \"pickled_novel_dict_0_50\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_fifty = pickle.load( open( \"pickled_novel_dict_50_100\", \"rb\" ) )\n",
    "# favorite_color is now { \"lion\": \"yellow\", \"kitty\": \"red\" }d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Pride and Prejudice', 'FrankensteinOrThe Modern Prometheus', 'A Journal of the Plague Year', 'The Importance of Being EarnestA Trivial Comedy for Serious People', 'The Works of Edgar Allan PoeThe Raven Edition', \"Alice's Adventures in Wonderland\", 'The Call of the Wild', 'Et dukkehjemEnglish', 'A Modest Proposal', 'The Strange Case of DrJekyll and MrHyde', 'A Tale of Two Cities', 'Treasure Island', 'The Yellow Wallpaper', 'Ion', 'Adventures of Huckleberry Finn', 'The Adventures of Sherlock Holmes', 'Anthem', 'The Adventures of Tom Sawyer', 'Moby DickOrThe Whale', 'A Christmas Carol in ProseBeing a Ghost Story of Christmas', 'Little Women', 'The Masque of the Red Death', 'Metamorphosis', 'Heart of Darkness', 'GrimmsFairy Tales', 'The Picture of Dorian Gray', 'Emma', 'The Hound of the Baskervilles', 'Waldenand On The Duty Of Civil Disobedience', 'Peter Pan', 'The Decameron of Giovanni Boccaccio', 'Dracula', 'The Awakeningand Selected Short Stories', 'Jane EyreAn Autobiography', 'The Scarlet Letter', 'Great Expectations', 'War and Peace', 'The Secret Garden', 'Il PrincipeEnglish', 'The War of the Worlds', 'BeowulfAn Anglo-Saxon Epic Poem', 'The Wonderful Wizard of Oz', 'The Count of Monte CristoIllustrated', 'Anne of Green Gables', 'Ulysses', 'The MemoirsCorrespondenceAnd MiscellaniesFrom The Papers Of Thomas Jefferson', 'The Mysterious Affair at Styles', 'Oliver Twist', 'Pygmalion'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_fifty.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
